{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE MNIST DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mnistdata.png](img/Mnistdata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Description\n",
    "This notebook contains information about the MNIST data set.The purpose of this notebook is to explain how to\n",
    "read the MNIST dataset efficiently into memory in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.What is the MNIST dataset?\n",
    "The MNIST problem is a dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem. Images of digits were taken from a variety of scanned documents, normalized in size and centered. MNIST contains 70,000 images of handwritten digits: 60,000 for training and 10,000 for testing.\n",
    "\n",
    "#### The dataset consists of pair, “handwritten digit image” and “label”. Digit ranges from 0 to 9, meaning 10 patterns in total.\n",
    "- __handwritten digit image:__ This is gray scale image with size 28 x 28 pixel  square (784 pixels total). A standard spit of the dataset is used to evaluate and compare models, where 60,000 images are used to train a model and a separate set of 10,000 images are used to test it.\n",
    "- __label :__ This is actual digit number this handwritten digit image represents. It is either  0 to 9. Results are reported using prediction error, which is nothing more than the inverted classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mnist_plot.png](img/mnist_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How is stored?\n",
    "The training and testing data of the MNIST database is stored in compressed IDX formatted files. It is a binary file format. The IDX file format is a simple format for vectors and multidimensional matrices of various numerical types. Reason for storing data in that format is a performance and memory requirements. Binary file formats are far better than text file formats like CSV. Storing data in binary format takes less memory, which is really an added advantage when a large volume of data needs to be stored. Information about __IDX file format__ can be found [here](http://www.fon.hum.uva.nl/praat/manual/IDX_file_format.html).\n",
    "\n",
    "The basic format is\n",
    "\n",
    "magic number<br>\n",
    " size in dimension 0<br>\n",
    " size in dimension 1<br>\n",
    " size in dimension 2<br>\n",
    " …..<br>\n",
    " size in dimension N<br>\n",
    " data<br>\n",
    " \n",
    "The magic number is an integer (MSB first). The first 2 bytes are always 0.<br>\n",
    "\n",
    "The third byte codes the type of the data:<br>\n",
    " 0x08: unsigned byte<br>\n",
    " 0x09: signed byte<br>\n",
    " 0x0B: short (2 bytes)<br>\n",
    " 0x0C: int (4 bytes)<br>\n",
    " 0x0D: float (4 bytes)<br>\n",
    " 0x0E: double (8 bytes)<br>\n",
    " \n",
    "The 4-th byte codes the number of dimensions of the vector/matrix: 1 for vectors, 2 for matrices….<br>\n",
    "The sizes in each dimension are 4-byte integers (MSB first, high endian, like in most non-Intel processors).<br>\n",
    "The data is stored like in a C array, i.e. the index in the last dimension changes the fastest.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Explanation\n",
    "__TRAINING SET IMAGE FILE (train-images-idx3-ubyte):__<br>\n",
    "[offset] [type] [value] [description]<br>\n",
    " 0000 32 bit integer 0x00000803(2051) magic number<br>\n",
    " 0004 32 bit integer 60000 number of images<br>\n",
    " 0008 32 bit integer 28 number of rows<br>\n",
    " 0012 32 bit integer 28 number of columns<br>\n",
    " 0016 unsigned byte ?? pixel<br>\n",
    " 0017 unsigned byte ?? pixel<br>\n",
    " ……..<br>\n",
    " xxxx unsigned byte ?? pixel<br>\n",
    " \n",
    "In magic number magic number the first two digits are 0x00 and 0x00, where each HEX digit is represented by 4 binary bits. So, two HEX digits makes a 8-bit binary number or a byte. The 3rd byte is the type of data, which is 0x08, the data format is unsigned byte having value from 0 to 255. The 4th byte is the number of dimensions, which is 0x03. The next 3 bytes give information about the sizes of the data in the 3 dimensions.<br>\n",
    "Each byte from 16th byte onward, contains pixel data, and the type of the data is unsigned byte, i.e. each pixel data is contained in a 8-bit binary digit, having value from 0 to 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare the data\n",
    "Remember to download four files wich are required for this notebook:\n",
    "\n",
    "- train-images-idx3-ubyte: training set images \n",
    "- labels-idx1-ubyte: training set labels \n",
    "- t10k-images-idx3-ubyte:  test set images \n",
    "- t10k-labels-idx1-ubyte:  test set labels\n",
    "\n",
    "You can find them under this [link](http://yann.lecun.com/exdb/mnist/). Next create folder called __data__ and save those files. \n",
    "\n",
    "\n",
    "Reading the uncompressed file train-images-idx3-ubyte with 60000 images of 28×28 pixel data, will result in a new Matrix object with 60000 rows and 784 (=28×28) columns. Each cell will contain a number in the interval from 0 to 255.\n",
    "\n",
    "Reading the uncompressed file train-labels-idx1-ubyte with 60000 labels will result in a new Matrix object with 1 row and 60000 columns. Each cell will contain a number in the interval from 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1 Unzip the files \n",
    "To unzip the files we can use Python Library which is called __gzip__ . Source code and more information about it can be found  [here](https://docs.python.org/3/library/gzip.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 TEST SET IMAGE FILE (t10k-images-idx3-ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code adapted from https://docs.python.org/3/library/gzip.html\n",
    "# Import gzip\n",
    "import gzip \n",
    "\n",
    "# Open test file with images and read bytes from files\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 TEST SET LABEL FILE (t10k-labels-idx1-ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code adapted from https://docs.python.org/3/library/gzip.html\n",
    "# Import gzip\n",
    "import gzip \n",
    "\n",
    "# Open test file with labels and read bytes from files\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.2 Determine file type\n",
    "Python supports a range of types to store sequences. There are six sequence types: strings, byte sequences (bytes objects), byte arrays (bytearray objects), lists, tuples, and range objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 TEST SET IMAGE FILE (t10k-images-idx3-ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks type of file content\n",
    "type(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x08\\x03'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out what first 4 bits are\n",
    "file_content[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 TEST SET LABEL FILE (t10k-labels-idx1-ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks type of file content\n",
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x08\\x01'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out what first 4 bits are\n",
    "labels[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Convert Bytes to Integer\n",
    "The bytes type in Python is immutable and stores a sequence of values ranging from 0-255 (8-bits). You can get the value of a single byte by using an index like an array, but the values can not be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 TEST SET IMAGE FILE (t10k-images-idx3-ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source code adapted from: https://docs.python.org/3/library/stdtypes.html\n",
    "# First four bytes to int\n",
    "int.from_bytes(file_content[0:4], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 TEST SET LABEL FILE (t10k-labels-idx1-ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source code adapted from: https://docs.python.org/3/library/stdtypes.html\n",
    "# First four bytes to int\n",
    "int.from_bytes(labels[0:4], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source code adapted from: https://docs.python.org/3/library/stdtypes.html\n",
    "# First four bytes to int\n",
    "int.from_bytes(b'\\x00\\x00\\x08\\x03', byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source code adapted from: https://docs.python.org/3/library/stdtypes.html\n",
    "# First four bytes to int\n",
    "int.from_bytes(b'\\x00\\x00\\x08\\x01', byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __byteorder__ argument determines the byte order used to represent the integer. If byteorder is \"big\", the most significant byte is at the beginning of the byte array. If byteorder is \"little\", the most significant byte is at the end of the byte array. Check this [link](https://en.wikipedia.org/wiki/Endianness) if you want to find out more about little and big endian.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in a file: 10000. \n",
      "Number of rows in a file: 28. \n",
      "Number of columns in a file: 28. \n"
     ]
    }
   ],
   "source": [
    "# TEST SET IMAGE FILE (t10k-images-idx3-ubyte)\n",
    "print(\"Number of images in a file: {}. \".format(int.from_bytes(file_content[4:8], byteorder='big')))\n",
    "print(\"Number of rows in a file: {}. \".format(int.from_bytes(file_content[8:12], byteorder='big')))\n",
    "print(\"Number of columns in a file: {}. \".format(int.from_bytes(file_content[12:16], byteorder='big')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in a file: 10000. \n",
      "Integer : 7 \n",
      "Integer : 9  \n"
     ]
    }
   ],
   "source": [
    "# TEST SET LABEL FILE (t10k-labels-idx1-ubyte)\n",
    "print(\"Number of items in a file: {}. \".format(int.from_bytes(labels[4:8], byteorder='big')))\n",
    "print(\"Integer : {} \".format(int.from_bytes(labels[8:9], byteorder='big')))\n",
    "print(\"Integer : {}  \".format(int.from_bytes(labels[15:16], byteorder='big')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = file_content[16:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks type of the file content\n",
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image to 28 by 28 numpy array as unsigned 8 bit integer\n",
    "image = ~np.array(list(file_content[16:800])).reshape(28,28).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x258ae794a58>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Shows image using \n",
    "plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Read a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(labels[8:9], byteorder=\"big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save image \n",
    "To save image from numpy array we can use __PIL__- Python Imaging Library which is a free library for the Python programming language that adds support for opening, manipulating, and saving many different image file formats. The Image module provides a class with the same name which is used to represent a PIL image. The module also provides a number of factory functions, including functions to load images from files, and to create new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code adaptedfrom:https://stackoverflow.com/questions/6915106/saving-a-numpy-array-as-an-image-instructions\n",
    "# Import Image from PIL \n",
    "from PIL import Image\n",
    "# Takes image from numpy array\n",
    "im = Image.fromarray(image)\n",
    "# Saves as png image\n",
    "im.save(\"img/number.png\")\n",
    "# Saves as jpeg image\n",
    "im.save(\"img/number.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Import Library and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Import MNIST from sklearn.datasets\n",
    "from sklearn.datasets import fetch_mldata\n",
    "# Import train_test_split for traning and spliting MNIST data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import matplotlib to show an images\n",
    "import matplotlib.pyplot as plt\n",
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamilka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Kamilka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression MNIST\n",
    "# Source code adapted from: https://www.codementor.io/mgalarny/making-your-first-machine-learning-classifier-in-scikit-learn-python-db7d7iqdh\n",
    "\n",
    "# Load the MNIST data\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "# There are 70,000 images (28 by 28 images for a dimensionality of 784)\n",
    "# Shows the amount of images in MNIST dataset\n",
    "print(mnist.data.shape)\n",
    "\n",
    "# There are 70,000 labels \n",
    "# Shows the amount of labels in MNIST dataset\n",
    "print(mnist.target.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Showing the Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splits the data into training and test data sets the test_size=1/7.0, training set size 60,000 images and the test set size of 10,000\n",
    "train_img, test_img, train_lbl, test_lbl = train_test_split(mnist.data, mnist.target, test_size=1/7.0, random_state=0)\n",
    "\n",
    "# Determine figure size\n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "# Loop through images and labels, shows the first five train images and the first five train labels\n",
    "for index, (image, label) in enumerate(zip(train_img[0:5], train_lbl[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap='gray')\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Measure Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: 0.9194\n"
     ]
    }
   ],
   "source": [
    "# Makes an instance of the Model\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs', multi_class='multinomial')\n",
    "# Trains the model on the data and stores the information learned from the data\n",
    "logisticRegr.fit(train_img, train_lbl)\n",
    "# Predicts the labels of new images\n",
    "logisticRegr.predict(test_img[0].reshape(1,-1))\n",
    "# Predict for Multiple Observations (images) at Once\n",
    "logisticRegr.predict(test_img[0:10])\n",
    "# Make predictions on entire test data\n",
    "predictions = logisticRegr.predict(test_img)\n",
    "# Measures Model Performance\n",
    "score = logisticRegr.score(test_img, test_lbl)\n",
    "\n",
    "print(\"Performance: {}\" .format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.References:\n",
    "\n",
    "https://corochann.com/mnist-dataset-introduction-1138.html\n",
    "\n",
    "https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "\n",
    "https://www.w3resource.com/python/python-bytes.php\n",
    "\n",
    "https://docs.python.org/3/library/gzip.html\n",
    "\n",
    "https://docs.python.org/3/library/stdtypes.html\n",
    "\n",
    "https://medium.com/@mannasiladittya/converting-mnist-data-in-idx-format-to-python-numpy-array-5cb9126f99f1\n",
    "\n",
    "https://pillow.readthedocs.io/en/3.1.x/reference/Image.html\n",
    "\n",
    "https://www.codementor.io/mgalarny/making-your-first-machine-learning-classifier-in-scikit-learn-python-db7d7iqdh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
