{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/deepLearning.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Description\n",
    "This jupyter notebook contains information explaining Digit recognition Python script. I’ll  discuss what technologies were used in the script and step by step how it works with explanations and samples of code. Also describe in brief what is neural network, popular classification of algorithms used  to recognize handwritten numbers.The  goal of this notebook is to show how to recognize handwritten digit using a simple Multi-Layer Perceptron (MLP) in Keras and how to build a near state-of-the-art deep neural network model using Python and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is a neural network?\n",
    "A neural network is a type of machine learning which models itself after the human brain. This creates an artificial neural network that via an algorithm allows the computer to learn by incorporating new data.The computer with the neural network is taught to do a task by having it analyze training examples, which have been previously labeled in advance. A common example of a task for a neural network using deep learning is an object recognition task, where the neural network is presented with a large number of objects of a certain type, such as a cat, or a street sign, and the computer, by analyzing the recurring patterns in the presented images, learns to categorize new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 How a deep learning neural network learns?\n",
    "A multilayer perceptron (MLP) has one or more hidden layers along with the input and output layers, each layer contains several neurons that interconnect with each other by weight links. The number of neurons in the input layer will be the number of attributes in the dataset, neurons in the output layer will be the number of classes given in the dataset.For a basic idea of how a deep learning neural network learns, imagine a factory line. After the raw materials (the data set) are input, they are then passed down the conveyer belt, with each subsequent stop or layer extracting a different set of high-level features. If the network is intended to recognize an object, the first layer might analyze the brightness of its pixels.The next layer could then identify any edges in the image, based on lines of similar pixels. After this, another layer may recognize textures and shapes, and so on. By the time the fourth or fifth layer is reached, the deep learning net will have created complex feature detectors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_network.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Digit recognition script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "This is a step-by-step plan that I will follow in this notbook to create digits recognition script.<br>\n",
    "<img src=\"img/Pipeline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1. Get the following packages and libraries\n",
    "__- [Python](https://www.python.org/)__<br>\n",
    "__- [NumPy](http://www.numpy.org/)__<br>\n",
    "__- [Matplotlib](https://matplotlib.org/)__<br>\n",
    "__- [Theano](http://deeplearning.net/software/theano/) or [TensorFlow](https://www.tensorflow.org/)__<br>\n",
    "__- [Keras](https://keras.io/)__<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Imports\n",
    "Organise the following imports that you will need to build neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "# Import numpy to perform matrix/vector operations\n",
    "import numpy as np\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Import Sequential model which is a linear stack of layers\n",
    "from keras.models import Sequential\n",
    "#Keras Imports to create the neural network model with neurons, layers and other utilities.\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "# Import MNIST datase\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "# Import Image for operation on image(save,open, etc)\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Define user inputs\n",
    "__- nb_epoch__ - Number of iterations needed for the network to minimize the loss function<br>\n",
    "__- num_classes__ - Total number of class labels or classes involved in the classification problem.<br>\n",
    "__- batch_size__ - Number of images given to the model.<br>\n",
    "__- train_size__ - Number of training images to train the model.<br>\n",
    "__- test_size__ - Number of testing images to test the model.<br>\n",
    "__- v_length__ - Dimension of flattened input image size i.e. if input image size is 28x28, then v_length = 784.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes a random seed for reproducibility\n",
    "np.random.seed(9)\n",
    "\n",
    "# User inputs\n",
    "nb_epoch = 25 \n",
    "num_classes = 10\n",
    "batch_size = 128 \n",
    "train_size = 60000\n",
    "test_size = 10000 \n",
    "v_length = 784 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Prepare the dataset\n",
    "We are loading the MNIST dataset by calling mnist.load_data() function in Keras. Then returns two tuples that are holds train data and train label in first tuple, and test data and test label in second tuple.When data is loaded we need to analyze and pre-process the dataset that the model can understand it.\n",
    "This will takes the following steps:\n",
    "#### 4.1 Split the mnist data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (60000, 28, 28)\n",
      "Test data shape: (10000, 28, 28)\n",
      "Train samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Splits the MNIST data into train and test\n",
    "(trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
    "# Output train data shape\n",
    "print (\"Train data shape: {}\".format(trainData.shape))\n",
    "# Output test data shape\n",
    "print (\"Test data shape: {}\".format(testData.shape))\n",
    "# Output train samples\n",
    "print( \"Train samples: {}\".format(trainData.shape[0]))\n",
    "# Output train samples test samples\n",
    "print (\"Test samples: {}\".format(testData.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Reshape the dataset\n",
    "To achieve this we can use NumPy’s reshape function. In Deep Learning, we provide the raw pixel intensities of images as inputs to the neural nets. The original data and label, are images  of dimensions 28x28. If we flatten it, we will get 28x28=784 pixel intensities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshapes the dataset\n",
    "trainData = trainData.reshape(train_size, v_length) # Reshapes the train data\n",
    "testData = testData.reshape(test_size, v_length) # Reshapes the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data type\n",
    "This can be change using .astype function provided by NumPy.Change the pixel intensities to float32 datatype. As grayscale image pixel intensities are integers in the range 0-255, we can convert them to floating point representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.astype(\"float32\") # For train data change the pixel intensities to float32\n",
    "testData = testData.astype(\"float32\") # For test data change the pixel intensities to float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Normalize\n",
    "These MNIST images of 28×28 pixels are represented as an array of numbers whose values range from 0-255 of type uint8. But it is usual to scale the input values of neural networks to certain ranges.I have normalize these floating point values in the range (0-1) to improve computational efficiency as well as to follow the standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData /= 255 # grayscale image pixel intensities are integers in the range [0-255]\n",
    "testData /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Output reshaped train  and test data \n",
    "We can verify that trainData.shape takes the form of (60000, 784) and testData.shape takes the form of (10000, 784), where the first dimension indexes the image and the second indexes the pixel in each image (now the intensity of the pixel is a value between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (60000, 784)\n",
      "Test data shape: (10000, 784)\n",
      "Train samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "#Output reshaped train data \n",
    "print (\"Train data shape: {}\".format(trainData.shape))\n",
    "# Output reshaped test data  \n",
    "print (\"Test data shape: {}\".format(testData.shape))\n",
    "# Output reshaped train samples  \n",
    "print (\"Train samples: {}\".format(trainData.shape[0]))\n",
    "# Output reshaped test samples\n",
    "print (\"Test samples: {}\".format(testData.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 One Hot Encoding\n",
    "A one hot encoding is a representation of categorical variables as binary vectors.This first requires that the categorical values be mapped to integer values. The Keras library offers a function np_utils.to_categorical function, which takes in labels and number of class labels as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices --> one-hot encoding\n",
    "mTrainLabels = np_utils.to_categorical(trainLabels, num_classes)\n",
    "mTestLabels = np_utils.to_categorical(testLabels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 Create the model\n",
    "The main data structure in Keras is the Sequential class, which allows the creation of a basic neural network. Keras also offers an API that allows implementing more complex models in the form of a graph that can have multiple inputs, multiple outputs. In Keras we can find all the required types of layers that can be added to the model through the add() method. Find out more about creating the mode with [Keras](https://keras.io/models/model/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptron (MLP) will be use as neural network model with 784 input neurons. Also we will use two hidden layers. First one contains 512 neurons and second layer contains 256 neurons, followed by a fully connected layer of 10 neurons for taking the probabilities of all the class labels.[ReLU](https://keras.io/activations/) is used as the activation function for hidden layers and [softmax](https://keras.io/activations/) is used as the activation function for output layer. Add the and we can sumerized the model and output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               5632      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 675,348\n",
      "Trainable params: 675,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Two hidden layers are used with 512 neurons in hidden layer 1 a\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"relu\")) # Activation function for hidden layers\n",
    "model.add(Dropout(0.2)) # 20% is used as is a weight constraint on those layers\n",
    "model.add(Dense(256)) #  256 neurons in hidden layer 2\n",
    "model.add(Activation(\"relu\"))  # Activation function for hidden layers\n",
    "model.add(Dropout(0.2))# 20% is used as is a weight constraint on those layers\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\")) #  Activation function for output layer.\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 Compile the model\n",
    "Next step is to indicate the metric that we will use to monitor the learning process (and test) of neural network. __categorical_crossentropy__ as the loss function (as this is a multi-label classification problem), __adam__ (gradient descent algorithm) as the optimizer and __accuracy__ as our performance metric. More information about compiling the model you can find under this [link](https://keras.io/models/model/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles the model\n",
    "# categorical_crossentropy as the loss function, adam as the optimizer and accuracy as our performance metric.\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 Fit the model\n",
    "To fit our model we can use a function called __model.fit__. This function requires some arguments such as : trainData,mTrainLabels,validation_data,batch_size,nb_epoch that we created before. Verbose argument is for debugging purposes.\n",
    "I used __history__ object to analyse how our model gets trained with the dataset which is also provided by Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamilka\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      " - 11s - loss: 0.4827 - acc: 0.8463 - val_loss: 0.1430 - val_acc: 0.9596\n",
      "Epoch 2/25\n",
      " - 11s - loss: 0.1504 - acc: 0.9573 - val_loss: 0.1138 - val_acc: 0.9679\n",
      "Epoch 3/25\n",
      " - 11s - loss: 0.1058 - acc: 0.9693 - val_loss: 0.1005 - val_acc: 0.9717\n",
      "Epoch 4/25\n",
      " - 11s - loss: 0.0870 - acc: 0.9747 - val_loss: 0.0875 - val_acc: 0.9758\n",
      "Epoch 5/25\n",
      " - 11s - loss: 0.0736 - acc: 0.9784 - val_loss: 0.0815 - val_acc: 0.9758\n",
      "Epoch 6/25\n",
      " - 11s - loss: 0.0624 - acc: 0.9816 - val_loss: 0.0731 - val_acc: 0.9805\n",
      "Epoch 7/25\n",
      " - 12s - loss: 0.0529 - acc: 0.9847 - val_loss: 0.0751 - val_acc: 0.9805\n",
      "Epoch 8/25\n",
      " - 11s - loss: 0.0508 - acc: 0.9847 - val_loss: 0.0745 - val_acc: 0.9815\n",
      "Epoch 9/25\n",
      " - 11s - loss: 0.0479 - acc: 0.9865 - val_loss: 0.0812 - val_acc: 0.9799\n",
      "Epoch 10/25\n",
      " - 11s - loss: 0.0437 - acc: 0.9874 - val_loss: 0.0831 - val_acc: 0.9781\n",
      "Epoch 11/25\n",
      " - 11s - loss: 0.0388 - acc: 0.9886 - val_loss: 0.0756 - val_acc: 0.9815\n",
      "Epoch 12/25\n",
      " - 11s - loss: 0.0352 - acc: 0.9899 - val_loss: 0.0752 - val_acc: 0.9805\n",
      "Epoch 13/25\n",
      " - 11s - loss: 0.0343 - acc: 0.9898 - val_loss: 0.0692 - val_acc: 0.9808\n",
      "Epoch 14/25\n",
      " - 11s - loss: 0.0331 - acc: 0.9901 - val_loss: 0.0737 - val_acc: 0.9829\n",
      "Epoch 15/25\n",
      " - 11s - loss: 0.0317 - acc: 0.9911 - val_loss: 0.0736 - val_acc: 0.9823\n",
      "Epoch 16/25\n",
      " - 11s - loss: 0.0293 - acc: 0.9914 - val_loss: 0.0668 - val_acc: 0.9838\n",
      "Epoch 17/25\n",
      " - 11s - loss: 0.0280 - acc: 0.9919 - val_loss: 0.0754 - val_acc: 0.9829\n",
      "Epoch 18/25\n",
      " - 11s - loss: 0.0275 - acc: 0.9919 - val_loss: 0.0782 - val_acc: 0.9801\n",
      "Epoch 19/25\n",
      " - 11s - loss: 0.0245 - acc: 0.9930 - val_loss: 0.0737 - val_acc: 0.9814\n",
      "Epoch 20/25\n",
      " - 11s - loss: 0.0217 - acc: 0.9938 - val_loss: 0.0777 - val_acc: 0.9836\n",
      "Epoch 21/25\n",
      " - 11s - loss: 0.0248 - acc: 0.9926 - val_loss: 0.0865 - val_acc: 0.9818\n",
      "Epoch 22/25\n",
      " - 11s - loss: 0.0256 - acc: 0.9926 - val_loss: 0.0815 - val_acc: 0.9833\n",
      "Epoch 23/25\n",
      " - 10s - loss: 0.0210 - acc: 0.9938 - val_loss: 0.0756 - val_acc: 0.9822\n",
      "Epoch 24/25\n",
      " - 11s - loss: 0.0193 - acc: 0.9946 - val_loss: 0.0737 - val_acc: 0.9831\n",
      "Epoch 25/25\n",
      " - 11s - loss: 0.0195 - acc: 0.9942 - val_loss: 0.0811 - val_acc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "# Remove Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# fit the model\n",
    "history = model.fit(trainData, mTrainLabels,validation_data=(testData, mTestLabels),batch_size=batch_size,nb_epoch=nb_epoch,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 Evaluate the model\n",
    "To evaluate our model we can use function that is provided by Keras which is called __model.evaluate__. Thanks to this we can give a prediction to test data and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "# List all data in history\n",
    "print (history.history.keys())\n",
    "\n",
    "# Evaluate the model and makes prediction\n",
    "scores = model.evaluate(testData, mTestLabels, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://www.techradar.com/news/what-is-a-neural-network\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/08/evolution-core-concepts-deep-learning-neural-networks/\n",
    "\n",
    "https://www.digitaltrends.com/cool-tech/what-is-an-artificial-neural-network/\n",
    "\n",
    "https://gogul09.github.io/software/digits-recognition-mlp\n",
    "\n",
    "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "\n",
    "https://keras.io/models/model/\n",
    "\n",
    "https://towardsdatascience.com/deep-learning-for-beginners-practical-guide-with-python-and-keras-d295bfca4487"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
