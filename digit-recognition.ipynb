{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/deepLearning.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Description\n",
    "This jupyter notebook contains information explaining Digit recognition Python script. I’ll  discuss what technologies were used in the script and step by step how it works with explanations and samples of code. Also describe in brief what is neural network, popular classification of algorithms used  to recognize handwritten numbers.The  goal of this notebook is to show how to recognize handwritten digit using a simple Multi-Layer Perceptron (MLP) in Keras and how to build a near state-of-the-art deep neural network model using Python and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is a neural network?\n",
    "A neural network is a type of machine learning which models itself after the human brain. This creates an artificial neural network that via an algorithm allows the computer to learn by incorporating new data.The computer with the neural network is taught to do a task by having it analyze training examples, which have been previously labeled in advance. A common example of a task for a neural network using deep learning is an object recognition task, where the neural network is presented with a large number of objects of a certain type, such as a cat, or a street sign, and the computer, by analyzing the recurring patterns in the presented images, learns to categorize new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 How a deep learning neural network learns?\n",
    "A multilayer perceptron (MLP) has one or more hidden layers along with the input and output layers, each layer contains several neurons that interconnect with each other by weight links. The number of neurons in the input layer will be the number of attributes in the dataset, neurons in the output layer will be the number of classes given in the dataset.For a basic idea of how a deep learning neural network learns, imagine a factory line. After the raw materials (the data set) are input, they are then passed down the conveyer belt, with each subsequent stop or layer extracting a different set of high-level features. If the network is intended to recognize an object, the first layer might analyze the brightness of its pixels.The next layer could then identify any edges in the image, based on lines of similar pixels. After this, another layer may recognize textures and shapes, and so on. By the time the fourth or fifth layer is reached, the deep learning net will have created complex feature detectors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_network.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Digit recognition script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "This is a step-by-step plan that I will follow in this notbook to create digits recognition script.<br>\n",
    "<img src=\"img/Pipeline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1. Get the following packages and libraries\n",
    "__- [Python](https://www.python.org/)__<br>\n",
    "__- [NumPy](http://www.numpy.org/)__<br>\n",
    "__- [Matplotlib](https://matplotlib.org/)__<br>\n",
    "__- [Theano](http://deeplearning.net/software/theano/) or [TensorFlow](https://www.tensorflow.org/)__<br>\n",
    "__- [Keras](https://keras.io/)__<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Imports\n",
    "Organise the following imports that you will need to build neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "# Import numpy to perform matrix/vector operations\n",
    "import numpy as np\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Import Sequential model which is a linear stack of layers\n",
    "from keras.models import Sequential\n",
    "#Keras Imports to create the neural network model with neurons, layers and other utilities.\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "# Import MNIST datase\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "# Import Image for operation on image(save,open, etc)\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Define user inputs\n",
    "__- nb_epoch__ - Number of iterations needed for the network to minimize the loss function<br>\n",
    "__- num_classes__ - Total number of class labels or classes involved in the classification problem.<br>\n",
    "__- batch_size__ - Number of images given to the model.<br>\n",
    "__- train_size__ - Number of training images to train the model.<br>\n",
    "__- test_size__ - Number of testing images to test the model.<br>\n",
    "__- v_length__ - Dimension of flattened input image size i.e. if input image size is 28x28, then v_length = 784.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes a random seed for reproducibility\n",
    "np.random.seed(9)\n",
    "\n",
    "# User inputs\n",
    "nb_epoch = 25 \n",
    "num_classes = 10\n",
    "batch_size = 128 \n",
    "train_size = 60000\n",
    "test_size = 10000 \n",
    "v_length = 784 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Prepare the dataset\n",
    "We are loading the MNIST dataset by calling mnist.load_data() function in Keras. Then returns two tuples that are holds train data and train label in first tuple, and test data and test label in second tuple.When data is loaded we need to analyze and pre-process the dataset that the model can understand it.\n",
    "This will takes the following steps:\n",
    "#### 4.1 Split the mnist data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (60000, 28, 28)\n",
      "Test data shape: (10000, 28, 28)\n",
      "Train samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Splits the MNIST data into train and test\n",
    "(trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
    "# Output train data shape\n",
    "print (\"Train data shape: {}\".format(trainData.shape))\n",
    "# Output test data shape\n",
    "print (\"Test data shape: {}\".format(testData.shape))\n",
    "# Output train samples\n",
    "print( \"Train samples: {}\".format(trainData.shape[0]))\n",
    "# Output train samples test samples\n",
    "print (\"Test samples: {}\".format(testData.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Reshape the dataset\n",
    "To achieve this we can use NumPy’s reshape function. In Deep Learning, we provide the raw pixel intensities of images as inputs to the neural nets. The original data and label, are images  of dimensions 28x28. If we flatten it, we will get 28x28=784 pixel intensities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshapes the dataset\n",
    "trainData = trainData.reshape(train_size, v_length) # Reshapes the train data\n",
    "testData = testData.reshape(test_size, v_length) # Reshapes the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data type\n",
    "This can be change using .astype function provided by NumPy.Change the pixel intensities to float32 datatype. As grayscale image pixel intensities are integers in the range 0-255, we can convert them to floating point representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.astype(\"float32\") # For train data change the pixel intensities to float32\n",
    "testData = testData.astype(\"float32\") # For test data change the pixel intensities to float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Normalize\n",
    "We have normalize these floating point values in the range (0-1) to improve computational efficiency as well as to follow the standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData /= 255 # grayscale image pixel intensities are integers in the range [0-255]\n",
    "testData /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Output reshaped train  and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (60000, 784)\n",
      "Test data shape: (10000, 784)\n",
      "Train samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "#Output reshaped train data \n",
    "print (\"Train data shape: {}\".format(trainData.shape))\n",
    "# Output reshaped test data  \n",
    "print (\"Test data shape: {}\".format(testData.shape))\n",
    "# Output reshaped train samples  \n",
    "print (\"Train samples: {}\".format(trainData.shape[0]))\n",
    "# Output reshaped test samples\n",
    "print (\"Test samples: {}\".format(testData.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 One Hot Encoding\n",
    "A one hot encoding is a representation of categorical variables as binary vectors.This first requires that the categorical values be mapped to integer values. The Keras library offers a function np_utils.to_categorical function, which takes in labels and number of class labels as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices --> one-hot encoding\n",
    "mTrainLabels = np_utils.to_categorical(trainLabels, num_classes)\n",
    "mTestLabels = np_utils.to_categorical(testLabels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://www.techradar.com/news/what-is-a-neural-network\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/08/evolution-core-concepts-deep-learning-neural-networks/\n",
    "\n",
    "https://www.digitaltrends.com/cool-tech/what-is-an-artificial-neural-network/\n",
    "\n",
    "https://gogul09.github.io/software/digits-recognition-mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
